{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "apparent-governor",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.057043,
     "end_time": "2021-05-27T09:53:38.493387",
     "exception": false,
     "start_time": "2021-05-27T09:53:38.436344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis and Building ML Model for Diabetes Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-dependence",
   "metadata": {
    "papermill": {
     "duration": 0.051304,
     "end_time": "2021-05-27T09:53:38.701752",
     "exception": false,
     "start_time": "2021-05-27T09:53:38.650448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.**\n",
    "\n",
    "**The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.**\n",
    "\n",
    "Id: Unique identifier for each data entry.\n",
    "\n",
    "Pregnancies: Number of times pregnant.\n",
    "\n",
    "Glucose: Plasma glucose concentration over 2 hours in an oral glucose tolerance test.\n",
    "\n",
    "BloodPressure: Diastolic blood pressure (mm Hg).\n",
    "\n",
    "SkinThickness: Triceps skinfold thickness (mm).\n",
    "\n",
    "Insulin: 2-Hour serum insulin (mu U/ml).\n",
    "\n",
    "BMI: Body mass index (weight in kg / height in m^2).\n",
    "\n",
    "DiabetesPedigreeFunction: Diabetes pedigree function, a genetic score of diabetes.\n",
    "\n",
    "Age: Age in years.\n",
    "\n",
    "Outcome: Binary classification indicating the presence (1) or absence (0) of diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-volleyball",
   "metadata": {
    "papermill": {
     "duration": 0.07477,
     "end_time": "2021-05-27T09:53:38.828031",
     "exception": false,
     "start_time": "2021-05-27T09:53:38.753261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-detail",
   "metadata": {
    "papermill": {
     "duration": 0.072534,
     "end_time": "2021-05-27T09:53:38.953872",
     "exception": false,
     "start_time": "2021-05-27T09:53:38.881338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-commander",
   "metadata": {
    "papermill": {
     "duration": 0.079459,
     "end_time": "2021-05-27T09:53:39.086446",
     "exception": false,
     "start_time": "2021-05-27T09:53:39.006987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-egyptian",
   "metadata": {
    "papermill": {
     "duration": 0.062366,
     "end_time": "2021-05-27T09:53:39.308640",
     "exception": false,
     "start_time": "2021-05-27T09:53:39.246274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of rows present in the dataset are: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-prototype",
   "metadata": {
    "papermill": {
     "duration": 0.074298,
     "end_time": "2021-05-27T09:53:39.436141",
     "exception": false,
     "start_time": "2021-05-27T09:53:39.361843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-weekly",
   "metadata": {
    "papermill": {
     "duration": 0.09029,
     "end_time": "2021-05-27T09:53:39.581425",
     "exception": false,
     "start_time": "2021-05-27T09:53:39.491135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-gallery",
   "metadata": {
    "papermill": {
     "duration": 0.974207,
     "end_time": "2021-05-27T09:53:40.609219",
     "exception": false,
     "start_time": "2021-05-27T09:53:39.635012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-answer",
   "metadata": {
    "papermill": {
     "duration": 0.063979,
     "end_time": "2021-05-27T09:53:40.727520",
     "exception": false,
     "start_time": "2021-05-27T09:53:40.663541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-victim",
   "metadata": {
    "papermill": {
     "duration": 0.197931,
     "end_time": "2021-05-27T09:53:40.980743",
     "exception": false,
     "start_time": "2021-05-27T09:53:40.782812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "labels = ['Diabetic', \n",
    "         'Non-Diabetic']\n",
    "percentages = [34.89, 65.10]\n",
    "explode=(0.1,0)\n",
    "ax.pie(percentages, explode=explode, labels=labels, autopct='%1.0f%%', \n",
    "       shadow=False, startangle=0,   \n",
    "       pctdistance=1.2,labeldistance=1.4)\n",
    "ax.legend(frameon=False, bbox_to_anchor=(1.5,0.8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-ministry",
   "metadata": {
    "papermill": {
     "duration": 0.055692,
     "end_time": "2021-05-27T09:53:41.093248",
     "exception": false,
     "start_time": "2021-05-27T09:53:41.037556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The distribution of the dependent variable is not skewed or imbalanced. We can move ahead with the same data without having to apply SMOTE or undersampling or oversampling techniques. But we do need to make that we distribution of the classes remain same when we split our data to train and test set.**\n",
    "\n",
    "**Before we move ahead, we need to check what are the minimum values for each column, certain columns like Glucose or Insulin can not have values as 0. Therefore, we need to take care of such values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-helmet",
   "metadata": {
    "papermill": {
     "duration": 0.06649,
     "end_time": "2021-05-27T09:53:41.215828",
     "exception": false,
     "start_time": "2021-05-27T09:53:41.149338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(\"The minimum value fore the columns {} is {}\".format(col, df[col].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-martin",
   "metadata": {
    "papermill": {
     "duration": 0.05539,
     "end_time": "2021-05-27T09:53:41.326665",
     "exception": false,
     "start_time": "2021-05-27T09:53:41.271275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Now out of the above columns having zero as their minima, only Pregnancie Column can take the values as zero, so what should do we do with those columns that have zero as their minimum even if they aren't supposed to?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-maximum",
   "metadata": {
    "papermill": {
     "duration": 0.055199,
     "end_time": "2021-05-27T09:53:41.437527",
     "exception": false,
     "start_time": "2021-05-27T09:53:41.382328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-market",
   "metadata": {
    "papermill": {
     "duration": 0.29704,
     "end_time": "2021-05-27T09:53:41.790784",
     "exception": false,
     "start_time": "2021-05-27T09:53:41.493744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def msv_1(data, thresh = 20, color = 'black', edgecolor = 'black', height = 3, width = 15):\n",
    "    \n",
    "    plt.figure(figsize = (width, height))\n",
    "    percentage = (data.isnull().mean()) * 100\n",
    "    percentage.sort_values(ascending = False).plot.bar(color = color, edgecolor = edgecolor)\n",
    "    plt.axhline(y = thresh, color = 'r', linestyle = '-')\n",
    "    \n",
    "    plt.title('Missing values percentage per column', fontsize=20, weight='bold' )\n",
    "    \n",
    "    plt.text(len(data.isnull().sum()/len(data))/1.7, thresh+2.5, f'Columns with more than {thresh}% missing values', fontsize=12, color='crimson',\n",
    "         ha='left' ,va='top')\n",
    "    plt.text(len(data.isnull().sum()/len(data))/1.7, thresh - 0.5, f'Columns with less than {thresh}% missing values', fontsize=12, color='green',\n",
    "         ha='left' ,va='top')\n",
    "    plt.xlabel('Columns', size=15, weight='bold')\n",
    "    plt.ylabel('Missing values percentage')\n",
    "    plt.yticks(weight ='bold')\n",
    "    \n",
    "    return plt.show()\n",
    "msv_1(df, 20, color=sns.color_palette('Reds',15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-front",
   "metadata": {
    "papermill": {
     "duration": 0.057139,
     "end_time": "2021-05-27T09:53:41.905539",
     "exception": false,
     "start_time": "2021-05-27T09:53:41.848400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**You might be wondering that there are no null values in the dataset, but are you sure? Remember what we had discussed in the previous section where certain columns were having zero as their minima eventhough they aren't supposed to. Those values will be considered as null values. Let's replace the zeros present in the Glucose, BloodPressure, SkinThickness, Insulin, and BMI columns with null.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-firewall",
   "metadata": {
    "papermill": {
     "duration": 0.070295,
     "end_time": "2021-05-27T09:53:42.033761",
     "exception": false,
     "start_time": "2021-05-27T09:53:41.963466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-private",
   "metadata": {
    "papermill": {
     "duration": 0.25534,
     "end_time": "2021-05-27T09:53:42.346529",
     "exception": false,
     "start_time": "2021-05-27T09:53:42.091189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "msv_1(df, 20, color=sns.color_palette('Reds',15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec184b36-d6fe-49f5-82d3-ca82f1bdf774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NULLs in the data\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-interest",
   "metadata": {
    "papermill": {
     "duration": 0.059692,
     "end_time": "2021-05-27T09:53:42.465738",
     "exception": false,
     "start_time": "2021-05-27T09:53:42.406046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We can observe that Insulin column has close to 50% zero or null values, followed by SkinThickness that has close to 30% missing values. We will be filling these values later.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-system",
   "metadata": {
    "papermill": {
     "duration": 0.058929,
     "end_time": "2021-05-27T09:53:42.585561",
     "exception": false,
     "start_time": "2021-05-27T09:53:42.526632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-middle",
   "metadata": {
    "papermill": {
     "duration": 0.059234,
     "end_time": "2021-05-27T09:53:42.703972",
     "exception": false,
     "start_time": "2021-05-27T09:53:42.644738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**In this section, we will be doing some basic Exploratory Data Analysis to get the \"feel\" of the data, we will be checking the distributions, the correlations etc of the different columns and try to remove the null values present.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-tractor",
   "metadata": {
    "papermill": {
     "duration": 1.132164,
     "end_time": "2021-05-27T09:53:43.895851",
     "exception": false,
     "start_time": "2021-05-27T09:53:42.763687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "ax_idx = 0\n",
    "columns = df.drop('Outcome', axis = 1).columns\n",
    "for col in columns:\n",
    "    df[col].plot(kind = 'hist', ax = axes[ax_idx], title = col, color = next(color_cycle))\n",
    "    ax_idx += 1\n",
    "\n",
    "plt.suptitle('Sales Trend according to Departments')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-duncan",
   "metadata": {
    "papermill": {
     "duration": 0.08545,
     "end_time": "2021-05-27T09:53:44.042902",
     "exception": false,
     "start_time": "2021-05-27T09:53:43.957452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Let's check the skewness of each of the columns.**\n",
    "\n",
    "**Skewness refers to the amount of asymmetry in the given feature or in other words amount of distortions from the normal distribution. The peak of the histogram represents the mode.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-defeat",
   "metadata": {
    "papermill": {
     "duration": 0.07352,
     "end_time": "2021-05-27T09:53:44.178757",
     "exception": false,
     "start_time": "2021-05-27T09:53:44.105237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "for col in df.drop('Outcome', axis = 1).columns:\n",
    "    print(\"Skewness for the column {} is {}\".format(col, df[col].skew()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-profile",
   "metadata": {
    "papermill": {
     "duration": 0.060787,
     "end_time": "2021-05-27T09:53:44.301683",
     "exception": false,
     "start_time": "2021-05-27T09:53:44.240896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Columns like Pregnancies, Glucose, BloodPressure, SkinThickness and BMI are not that much skewed. We can fill null values with the mean for these columns, but for columns like Insulin and DiabetesPedigreeFunction, we will have to replace them will median due to the effect of skewness.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5c95a-6961-43fb-8c21-efa1af87fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "df_cut=df.copy()\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(df_cut[['Glucose', 'BloodPressure', 'SkinThickness', 'BMI']])\n",
    "df_cut[['Glucose', 'BloodPressure', 'SkinThickness', 'BMI']] = imputer.transform(df[['Glucose', 'BloodPressure', 'SkinThickness', 'BMI']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-library",
   "metadata": {
    "papermill": {
     "duration": 0.070933,
     "end_time": "2021-05-27T09:53:44.433673",
     "exception": false,
     "start_time": "2021-05-27T09:53:44.362740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Insulin'] = df['Insulin'].fillna(df['Insulin'].median()) # Filling null values with the median.\n",
    "\n",
    "for col in ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI']:\n",
    "    df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-italic",
   "metadata": {
    "papermill": {
     "duration": 0.256194,
     "end_time": "2021-05-27T09:53:44.751130",
     "exception": false,
     "start_time": "2021-05-27T09:53:44.494936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "msv_1(df, 10, color=sns.color_palette('Greens',15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-miller",
   "metadata": {
    "papermill": {
     "duration": 0.072355,
     "end_time": "2021-05-27T09:53:44.887074",
     "exception": false,
     "start_time": "2021-05-27T09:53:44.814719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0f3cf-f149-4179-b255-1a98987681d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut,df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-pepper",
   "metadata": {
    "papermill": {
     "duration": 0.06446,
     "end_time": "2021-05-27T09:53:45.014489",
     "exception": false,
     "start_time": "2021-05-27T09:53:44.950029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**All null values are taken care of now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-vinyl",
   "metadata": {
    "papermill": {
     "duration": 0.070481,
     "end_time": "2021-05-27T09:53:45.148511",
     "exception": false,
     "start_time": "2021-05-27T09:53:45.078030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_target(var):\n",
    "    \"\"\"\n",
    "    A function that will return the mean values for 'var' column depending on whether the person\n",
    "    is diabetic or not\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(df.groupby('Outcome').mean()[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-native",
   "metadata": {
    "papermill": {
     "duration": 0.071007,
     "end_time": "2021-05-27T09:53:45.283536",
     "exception": false,
     "start_time": "2021-05-27T09:53:45.212529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distplot(col_name):\n",
    "    \"\"\"\n",
    "    A function that will plot the distribution of column 'col_name' for diabetic and non-diabetic people separately\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    sns.histplot(df[col_name][df.Outcome == 1], color =\"red\",kde=True)\n",
    "    sns.histplot(df[col_name][df.Outcome == 0], color =\"lightblue\",kde=True)\n",
    "    plt.legend(['Diabetes', 'No Diabetes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-margin",
   "metadata": {
    "papermill": {
     "duration": 0.062968,
     "end_time": "2021-05-27T09:53:45.410241",
     "exception": false,
     "start_time": "2021-05-27T09:53:45.347273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pregnancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-visiting",
   "metadata": {
    "papermill": {
     "duration": 0.361792,
     "end_time": "2021-05-27T09:53:45.835432",
     "exception": false,
     "start_time": "2021-05-27T09:53:45.473640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distplot('Pregnancies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-climate",
   "metadata": {
    "papermill": {
     "duration": 0.078508,
     "end_time": "2021-05-27T09:53:45.978315",
     "exception": false,
     "start_time": "2021-05-27T09:53:45.899807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_target('Pregnancies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-ethiopia",
   "metadata": {
    "papermill": {
     "duration": 0.065106,
     "end_time": "2021-05-27T09:53:46.109033",
     "exception": false,
     "start_time": "2021-05-27T09:53:46.043927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We can see that the number of pregnancies is high for the diabetic people**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-contact",
   "metadata": {
    "papermill": {
     "duration": 0.065105,
     "end_time": "2021-05-27T09:53:46.239515",
     "exception": false,
     "start_time": "2021-05-27T09:53:46.174410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Insulin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-rescue",
   "metadata": {
    "papermill": {
     "duration": 0.518087,
     "end_time": "2021-05-27T09:53:46.822987",
     "exception": false,
     "start_time": "2021-05-27T09:53:46.304900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distplot('Insulin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-border",
   "metadata": {
    "papermill": {
     "duration": 0.082241,
     "end_time": "2021-05-27T09:53:46.972789",
     "exception": false,
     "start_time": "2021-05-27T09:53:46.890548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_target('Insulin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-virginia",
   "metadata": {
    "papermill": {
     "duration": 0.066525,
     "end_time": "2021-05-27T09:53:47.105855",
     "exception": false,
     "start_time": "2021-05-27T09:53:47.039330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Diabetic People tend to have more Insulin level.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-chase",
   "metadata": {
    "papermill": {
     "duration": 0.066417,
     "end_time": "2021-05-27T09:53:47.239847",
     "exception": false,
     "start_time": "2021-05-27T09:53:47.173430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## BloodPressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-orleans",
   "metadata": {
    "papermill": {
     "duration": 0.416501,
     "end_time": "2021-05-27T09:53:47.722986",
     "exception": false,
     "start_time": "2021-05-27T09:53:47.306485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distplot('BloodPressure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-bible",
   "metadata": {
    "papermill": {
     "duration": 0.080212,
     "end_time": "2021-05-27T09:53:47.870943",
     "exception": false,
     "start_time": "2021-05-27T09:53:47.790731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_target('BloodPressure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-soundtrack",
   "metadata": {
    "papermill": {
     "duration": 0.068917,
     "end_time": "2021-05-27T09:53:48.008010",
     "exception": false,
     "start_time": "2021-05-27T09:53:47.939093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The mean of the blood pressure is greater for diabetic people as compared to the non-diabetic people**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-transportation",
   "metadata": {
    "papermill": {
     "duration": 0.067775,
     "end_time": "2021-05-27T09:53:48.144012",
     "exception": false,
     "start_time": "2021-05-27T09:53:48.076237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-migration",
   "metadata": {
    "papermill": {
     "duration": 0.368795,
     "end_time": "2021-05-27T09:53:48.581840",
     "exception": false,
     "start_time": "2021-05-27T09:53:48.213045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distplot('Glucose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-review",
   "metadata": {
    "papermill": {
     "duration": 0.082234,
     "end_time": "2021-05-27T09:53:48.732982",
     "exception": false,
     "start_time": "2021-05-27T09:53:48.650748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_target('Glucose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-selling",
   "metadata": {
    "papermill": {
     "duration": 0.070287,
     "end_time": "2021-05-27T09:53:48.874165",
     "exception": false,
     "start_time": "2021-05-27T09:53:48.803878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Diabetic People tend to have much higher Glucose level**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-victory",
   "metadata": {
    "papermill": {
     "duration": 0.07247,
     "end_time": "2021-05-27T09:53:49.018362",
     "exception": false,
     "start_time": "2021-05-27T09:53:48.945892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Comman Man Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-underwear",
   "metadata": {
    "papermill": {
     "duration": 0.070782,
     "end_time": "2021-05-27T09:53:49.202274",
     "exception": false,
     "start_time": "2021-05-27T09:53:49.131492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Let's think like a common man, and analyze the data.**\n",
    "\n",
    "**First, we would know what is the effect of Age on the Outcome because we have heard that as the age increases, the chances of diabetes also commonly increases.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-contest",
   "metadata": {
    "papermill": {
     "duration": 0.187835,
     "end_time": "2021-05-27T09:53:49.460648",
     "exception": false,
     "start_time": "2021-05-27T09:53:49.272813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Outcome', y = 'Age', data = df)\n",
    "plt.title('Age vs Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-characteristic",
   "metadata": {
    "papermill": {
     "duration": 0.071361,
     "end_time": "2021-05-27T09:53:49.604335",
     "exception": false,
     "start_time": "2021-05-27T09:53:49.532974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Yes, we were right, the median of the age of diabetic people is greater than that of non-diabetic people.**\n",
    "\n",
    "**Let's also check the effect of Blood Pressure on the Outcome.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-engineer",
   "metadata": {
    "papermill": {
     "duration": 0.186111,
     "end_time": "2021-05-27T09:53:49.862670",
     "exception": false,
     "start_time": "2021-05-27T09:53:49.676559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Outcome', y = 'BloodPressure', data = df)\n",
    "plt.title('BP vs Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-authority",
   "metadata": {
    "papermill": {
     "duration": 0.072098,
     "end_time": "2021-05-27T09:53:50.007486",
     "exception": false,
     "start_time": "2021-05-27T09:53:49.935388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The median of the BloodPressure of diabetic people lies close to the 75th Percentile of non-diabetic people.**\n",
    "\n",
    "**The next thing a common man would check is the relationship between age and BP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-perspective",
   "metadata": {
    "papermill": {
     "duration": 0.773227,
     "end_time": "2021-05-27T09:53:50.898587",
     "exception": false,
     "start_time": "2021-05-27T09:53:50.125360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='Age',y='BloodPressure', data=df, kind = 'reg', color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-management",
   "metadata": {
    "papermill": {
     "duration": 0.073096,
     "end_time": "2021-05-27T09:53:51.045982",
     "exception": false,
     "start_time": "2021-05-27T09:53:50.972886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Hmm, as the age increases, generally the Blood Pressure also increases**\n",
    "\n",
    "**One would also want to know the chances of getting diabetes, if it is common in the family. We can check that with the Diabetes Pedigree Function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-waste",
   "metadata": {
    "papermill": {
     "duration": 0.191293,
     "end_time": "2021-05-27T09:53:51.311888",
     "exception": false,
     "start_time": "2021-05-27T09:53:51.120595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_pal = {0: \"lightgreen\", 1: \"lightblue\"}\n",
    "sns.boxplot(x = 'Outcome', y = 'DiabetesPedigreeFunction', data = df)\n",
    "plt.title('DPF vs Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-voltage",
   "metadata": {
    "papermill": {
     "duration": 0.073923,
     "end_time": "2021-05-27T09:53:51.460819",
     "exception": false,
     "start_time": "2021-05-27T09:53:51.386896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Quite a proportion of people having high DPF does not end up having Diabetes.  But usually the diabetic people have DPF value close to 0.5 (50th Percentile)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-tracker",
   "metadata": {
    "papermill": {
     "duration": 0.073881,
     "end_time": "2021-05-27T09:53:51.610031",
     "exception": false,
     "start_time": "2021-05-27T09:53:51.536150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Gluscose Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-annex",
   "metadata": {
    "papermill": {
     "duration": 0.194342,
     "end_time": "2021-05-27T09:53:51.878724",
     "exception": false,
     "start_time": "2021-05-27T09:53:51.684382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_pal = {0: \"lightgrey\", 1: \"lightyellow\"}\n",
    "sns.boxplot(x = 'Outcome', y = 'Glucose', data = df)\n",
    "plt.title('Glucose vs Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-hebrew",
   "metadata": {
    "papermill": {
     "duration": 0.075593,
     "end_time": "2021-05-27T09:53:52.030036",
     "exception": false,
     "start_time": "2021-05-27T09:53:51.954443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Wow! the median of the Glucose level of Diabetic People is greater than the 75th Percentile of the glucose level of non-diabetic people. Therefore having a high glucose level does increase the chances of having diabetes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-scanner",
   "metadata": {
    "papermill": {
     "duration": 0.100456,
     "end_time": "2021-05-27T09:53:52.205994",
     "exception": false,
     "start_time": "2021-05-27T09:53:52.105538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Insulin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-external",
   "metadata": {
    "papermill": {
     "duration": 0.080728,
     "end_time": "2021-05-27T09:53:52.364546",
     "exception": false,
     "start_time": "2021-05-27T09:53:52.283818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Let's first check whether there is any relation between glucose and insulin level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-breast",
   "metadata": {
    "papermill": {
     "duration": 1.597989,
     "end_time": "2021-05-27T09:53:54.048382",
     "exception": false,
     "start_time": "2021-05-27T09:53:52.450393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='Insulin',y='Glucose', data=df, kind = 'reg', color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-database",
   "metadata": {
    "papermill": {
     "duration": 0.083791,
     "end_time": "2021-05-27T09:53:54.210822",
     "exception": false,
     "start_time": "2021-05-27T09:53:54.127031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We can see that as the insulin level increases, the Glucose level also increases.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-browser",
   "metadata": {
    "papermill": {
     "duration": 0.317995,
     "end_time": "2021-05-27T09:53:54.605871",
     "exception": false,
     "start_time": "2021-05-27T09:53:54.287876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Outcome', y = 'Insulin', data = df)\n",
    "plt.title('Insulin vs Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-detective",
   "metadata": {
    "papermill": {
     "duration": 0.078643,
     "end_time": "2021-05-27T09:53:54.766033",
     "exception": false,
     "start_time": "2021-05-27T09:53:54.687390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Body Mass Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-address",
   "metadata": {
    "papermill": {
     "duration": 0.078497,
     "end_time": "2021-05-27T09:53:54.923884",
     "exception": false,
     "start_time": "2021-05-27T09:53:54.845387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Body mass index (BMI) is a measure of body fat based on height and weight that applies to adult men and women. Does having a higher BMI leads to more chances of being diabetic? Let's check that out!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-louis",
   "metadata": {
    "papermill": {
     "duration": 0.191947,
     "end_time": "2021-05-27T09:53:55.195972",
     "exception": false,
     "start_time": "2021-05-27T09:53:55.004025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Outcome', y = 'BMI', data = df)\n",
    "plt.title('BMI vs Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-compression",
   "metadata": {
    "papermill": {
     "duration": 0.077773,
     "end_time": "2021-05-27T09:53:55.352379",
     "exception": false,
     "start_time": "2021-05-27T09:53:55.274606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Indeed, the Median BMI of the Diabetic People is greater than the Median BMI of the Non-Diabetic people.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-bradford",
   "metadata": {
    "papermill": {
     "duration": 0.077907,
     "end_time": "2021-05-27T09:53:55.508559",
     "exception": false,
     "start_time": "2021-05-27T09:53:55.430652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-symbol",
   "metadata": {
    "papermill": {
     "duration": 0.51738,
     "end_time": "2021-05-27T09:53:56.105437",
     "exception": false,
     "start_time": "2021-05-27T09:53:55.588057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-coast",
   "metadata": {
    "papermill": {
     "duration": 0.080308,
     "end_time": "2021-05-27T09:53:56.266600",
     "exception": false,
     "start_time": "2021-05-27T09:53:56.186292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**From the above heatmap, we can observe that all the features are weakly correlated, so that removes multicollinearity out of equation. Multicollinearity (also collinearity) is a phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy. Models like Logistic Regression assumes the presence of non-collinearity among the features, if multicollinearity is present it can lead to the bad performance of such models.**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07be35c9-b660-47dc-be37-8c3b8b574491",
   "metadata": {},
   "source": [
    "Z-score is used to quantify the ‘unusualness’ of an observation. A z-score is the number of standard deviations above/below the average. As an example, a z-score of -2 indicates that the observation is two standard deviations away below the average. The further away the observation’s z-score from 0, the more unusual it is. Z-score beyond 3 or below -3 indicates that the observation is an outlier we need to remove (outliers with |z-scores| less than or equal to 3 are not removed). The codes below are used to determine which observation is an outlier by calculating its z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc61ef-4009-4e1a-8233-4fe8ff89df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "outlBmi = list(np.where(np.abs(np.abs(zscore(df['BMI']))) > 3)[0])\n",
    "print(\"BMI Outliers: \", outlBmi)\n",
    "print(\"Total outlier BMI: \", len(outlBmi), \"\\n\")\n",
    "\n",
    "\n",
    "outlInsulin = list(np.where(np.abs(np.abs(zscore(df['Insulin']))) > 3)[0])\n",
    "print(\"Insulin Outliers: \", outlInsulin)\n",
    "print(\"Total outlier Insulin: \", len(outlInsulin), \"\\n\")\n",
    "\n",
    "outl = list(set(outlBmi + outlInsulin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf071b-7d6e-4f7f-b423-74d269348808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[outlInsulin, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f7b55-d5c2-4106-b34a-ce1d2d1e235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Outcome', y = 'BMI', data = df)\n",
    "plt.title('BMI vs Outcome')\n",
    "plt.show()\n",
    "\n",
    "df_outlier=df.copy()\n",
    "df_outlier.drop(df_outlier.index[list(outlInsulin)], inplace=True)\n",
    "\n",
    "sns.boxplot(x = 'Outcome', y = 'BMI', data = df_outlier)\n",
    "plt.title('BMI vs Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-poetry",
   "metadata": {
    "papermill": {
     "duration": 0.080629,
     "end_time": "2021-05-27T09:53:56.427896",
     "exception": false,
     "start_time": "2021-05-27T09:53:56.347267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Splitting and Features Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-accounting",
   "metadata": {
    "papermill": {
     "duration": 0.242074,
     "end_time": "2021-05-27T09:53:56.751024",
     "exception": false,
     "start_time": "2021-05-27T09:53:56.508950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Outcome', axis = 1)\n",
    "\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-freeze",
   "metadata": {
    "papermill": {
     "duration": 0.08077,
     "end_time": "2021-05-27T09:53:56.913076",
     "exception": false,
     "start_time": "2021-05-27T09:53:56.832306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Standardizing a dataset involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1.**\n",
    "\n",
    "**This can be thought of as subtracting the mean value or centering the data. Scaling the features is of utmost importance because different features are in different scales. Let's say the Age has values in double digits, whereas the DPF is of the kind float, the effect of the Age feature will be more as compared to the DPF**\n",
    "\n",
    "**Best practice is to use only the training set to figure out how to scale / normalize, then blindly apply the same transform to the test set.**\n",
    "\n",
    "**For example, say you're going to normalize the data by removing the mean and dividing out the variance. If you use the whole dataset to figure out the feature mean and variance, you're using knowledge about the distribution of the test set to set the scale of the training set - 'leaking' information.**\n",
    "\n",
    "**The right way to do this is to use only the training set to calculate the mean and variance, normalize the training set, and then at test time, use that same (training) mean and variance to normalize the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80805b7d-f295-40de-9ea2-8be5104b321b",
   "metadata": {},
   "source": [
    "#### The Big Question – Normalize or Standardize?\n",
    "\n",
    "Normalization vs. standardization is an eternal question among machine learning newcomers. Let me elaborate on the answer in this section.\n",
    "\n",
    "Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.\n",
    "\n",
    "Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization.\n",
    "\n",
    "However, at the end of the day, the choice of using normalization or standardization will depend on your problem and the machine learning algorithm you are using. There is no hard and fast rule to tell you when to normalize or standardize your data.\n",
    "\n",
    "Robust Scaler\n",
    "When working with outliers we can use Robust Scaling for scakling our data, It scales features using statistics that are robust to outliers. This method removes the median and scales the data in the range between 1st quartile and 3rd quartile. i.e., in between 25th quantile and 75th quantile range. This range is also called an Interquartile range. The median and the interquartile range are then stored so that it could be used upon future data using the transform method. If outliers are present in the dataset, then the median and the interquartile range provide better results and outperform the sample mean and variance. RobustScaler uses the interquartile range so that it is robust to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-suspect",
   "metadata": {
    "papermill": {
     "duration": 0.09783,
     "end_time": "2021-05-27T09:53:57.091690",
     "exception": false,
     "start_time": "2021-05-27T09:53:56.993860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train =  pd.DataFrame(sc.fit_transform(X_train),\n",
    "        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age'])\n",
    "X_test = pd.DataFrame(sc.fit_transform(X_test),\n",
    "        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-obligation",
   "metadata": {
    "papermill": {
     "duration": 0.081175,
     "end_time": "2021-05-27T09:53:57.254610",
     "exception": false,
     "start_time": "2021-05-27T09:53:57.173435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-admission",
   "metadata": {
    "papermill": {
     "duration": 0.090802,
     "end_time": "2021-05-27T09:53:57.426448",
     "exception": false,
     "start_time": "2021-05-27T09:53:57.335646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluation(model, x_train_std, y_train, x_test, y_test, train = True):\n",
    "    \"\"\"\n",
    "    A function that returns the score of every evaluation metrics\n",
    "    \"\"\"\n",
    "    if train == True:\n",
    "        pred = model.predict(x_train_std)\n",
    "        classifier_report = pd.DataFrame(classification_report(y_train, pred, output_dict = True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"F1 Score: {round(f1_score(y_train, pred), 2)}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{classifier_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    if train == False:\n",
    "        pred = model.predict(x_test)\n",
    "        classifier_report = pd.DataFrame(classification_report(y_test, pred, output_dict = True))\n",
    "        print(\"Test Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"F1 Score: {round(f1_score(y_test, pred), 2)}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{classifier_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-guarantee",
   "metadata": {
    "papermill": {
     "duration": 0.082187,
     "end_time": "2021-05-27T09:53:57.590649",
     "exception": false,
     "start_time": "2021-05-27T09:53:57.508462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-pressure",
   "metadata": {
    "papermill": {
     "duration": 0.197425,
     "end_time": "2021-05-27T09:53:57.869332",
     "exception": false,
     "start_time": "2021-05-27T09:53:57.671907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "evaluation(lr, X_train, y_train, X_test, y_test, True)\n",
    "print()\n",
    "evaluation(lr, X_train, y_train, X_test, y_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-worth",
   "metadata": {
    "papermill": {
     "duration": 0.081746,
     "end_time": "2021-05-27T09:53:58.033136",
     "exception": false,
     "start_time": "2021-05-27T09:53:57.951390",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-forth",
   "metadata": {
    "papermill": {
     "duration": 0.095818,
     "end_time": "2021-05-27T09:53:58.211044",
     "exception": false,
     "start_time": "2021-05-27T09:53:58.115226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_score_lr = round(accuracy_score(y_train, lr.predict(X_train)) * 100, 2)\n",
    "test_score_lr = round(accuracy_score(y_test, lr.predict(X_test)) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19306209-2ca8-44a8-b73a-f47f7ea5e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = list(lr.coef_[0])\n",
    "labels = list(df.columns[:-1])\n",
    "features = pd.DataFrame()\n",
    "features['Features'] = labels\n",
    "features['importance'] = coeff\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features['positive'] = features['importance'] > 0\n",
    "features.set_index('Features', inplace=True)\n",
    "features.importance.plot(kind='barh', figsize=(11, 6),color = features.positive.map({True: 'blue', False: 'red'}))\n",
    "plt.xlabel('Importance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-grant",
   "metadata": {
    "papermill": {
     "duration": 0.098515,
     "end_time": "2021-05-27T09:54:11.295997",
     "exception": false,
     "start_time": "2021-05-27T09:54:11.197482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "           'Train Accuracy': [train_score_lr],\n",
    "          'Test Accuracy' : [test_score_lr]\n",
    "         }\n",
    "\n",
    "models = pd.DataFrame(models, index = ['Logistic Regression'])\n",
    "models.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-representation",
   "metadata": {
    "papermill": {
     "duration": 0.086484,
     "end_time": "2021-05-27T09:54:11.639261",
     "exception": false,
     "start_time": "2021-05-27T09:54:11.552777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-racing",
   "metadata": {
    "papermill": {
     "duration": 119.825931,
     "end_time": "2021-05-27T09:56:11.550262",
     "exception": false,
     "start_time": "2021-05-27T09:54:11.724331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "random_state = 0\n",
    "lr=LogisticRegression(C=1,random_state = random_state)\n",
    "\n",
    "cv_results=(cross_val_score(lr, X_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=-1))\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-honor",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.098654,
     "end_time": "2021-05-27T09:56:11.736517",
     "exception": false,
     "start_time": "2021-05-27T09:56:11.637863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(cv_results),np.std(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac3b54-152b-4c6c-9162-db9d895eaf93",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527c267-53b2-4814-99c7-5d4e47588b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "estimator = LogisticRegression(random_state=random_state)\n",
    "rfecv = RFECV(estimator=estimator, cv=StratifiedKFold(10, random_state=random_state, shuffle=True), scoring=\"accuracy\")\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338d910-2ea0-44fd-b92f-80b8de67607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(rfecv.cv_results_[\"mean_test_score\"]) + 1), rfecv.cv_results_[\"mean_test_score\"], color='#303F9F', linewidth=3)\n",
    "plt.grid()\n",
    "plt.xticks(range(1, X.shape[1]+1))\n",
    "plt.xlabel(\"Number of Selected Features\")\n",
    "plt.ylabel(\"CV Score\")\n",
    "plt.title(\"Recursive Feature Elimination (RFE)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"The optimal number of features: {}\".format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38408ef-a5db-4b8b-84c5-91b5d1cf1fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = X.iloc[:, rfecv.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9679b0d-444d-41a7-b3f5-baaff07a7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\"X\\\" dimension: {}\".format(X.shape))\n",
    "print(\"\\\"X\\\" column list:\", X.columns.tolist())\n",
    "print(\"\\\"X_rfe\\\" dimension: {}\".format(X_rfe.shape))\n",
    "print(\"\\\"X_rfe\\\" column list:\", X_rfe.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b66c2-0986-435e-94fd-42fdc308380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_rfe_train, X_rfe_test, y_train, y_test = train_test_split(X, X_rfe, y, \n",
    "                                                                             train_size=0.8, \n",
    "                                                                             stratify=y,\n",
    "                                                                             random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfae42-b275-459d-96e5-5f2cbd51a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "print(\"Model training using original data: started!\")\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Model training using original data: done!\\n\")\n",
    "# Feature-selected dataset\n",
    "print(\"Model training using feature-selected data: started!\")\n",
    "rfecv = RFECV(estimator=estimator, cv=StratifiedKFold(10, random_state=random_state, shuffle=True), scoring=\"accuracy\")\n",
    "rfecv.fit(X_rfe_train, y_train)\n",
    "print(\"Model training using feature-selected data: done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a3a5a-56a3-40ca-903e-7f496aeca034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "acc = []\n",
    "y_pred = lr.predict(X_test)\n",
    "acc.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Feature selected dataset\n",
    "acc_rfe = []\n",
    "y_rfe_pred = rfecv.predict(X_rfe_test)\n",
    "acc_rfe.append(accuracy_score(y_test, y_rfe_pred))\n",
    "    \n",
    "acc_all = pd.DataFrame({\"Original dataset\": acc, \"Feature-selected dataset\": acc_rfe})\n",
    "acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c65cac-493e-48f1-992b-a8b764beea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "rfecv.fit(X_rfe_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve\n",
    "# calculating the probabilities\n",
    "y_rfe_pred  = rfecv.predict_proba(X_rfe_test)[:,1]\n",
    "y_pred  = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# instantiating the roc_cruve\n",
    "fpr,tpr,threshols=roc_curve(y_test,y_rfe_pred )\n",
    "\n",
    "fpr1,tpr1,threshols1=roc_curve(y_test,y_pred)\n",
    "\n",
    "\n",
    "# plotting the curve\n",
    "plt.plot([0,1],[0,1],\"k--\",'r+')\n",
    "plt.plot(fpr,tpr,'b',label='Logistic Regression')\n",
    "plt.plot(fpr1,tpr1,'r',label='Logistic Regression all')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Logistric Regression ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550921c8-44d2-4790-ae4c-a1cf7ec37344",
   "metadata": {},
   "source": [
    "### Interpreting ROC Plot:\n",
    "\n",
    "Interpreting the ROC plot is very different from a regular line plot. Because, though there is an X and a Y-axis, we don't read it as: for an X value of 0.25, the Y value is .9.\n",
    "\n",
    "Instead, what we have here is a line that traces the probability cutoff from 1 at the bottom-left to 0 in the top right.\n",
    "\n",
    "This is a way of analyzing how the sensitivity and specificity perform for the full range of probability cutoffs, that is from 0 to 1.\n",
    "\n",
    "Ideally, if we have a perfect model, all the events will have a probability score of 1 and all non-events will have a score of 0. For such a model, the area under the ROC will be a perfect 1.\n",
    "\n",
    "So, if we trace the curve from bottom left, the value of probability cutoff decreases from 1 towards 0. If we have a good model, more of the real events should be predicted as events, resulting in high sensitivity and low FPR. In that case, the curve will rise steeply covering a large area before reaching the top-right.\n",
    "\n",
    "Therefore, the larger the area under the ROC curve, the better is the model.\n",
    "\n",
    "The ROC curve is the only metric that measures how well the model does for different values of prediction probability cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f75bf-9830-46b9-8158-c036510ddc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_logreg = cross_val_score(rfecv, X_rfe_train, y_train, cv = kfold, scoring = 'roc_auc').mean()\n",
    "roc_auc_logreg_all = cross_val_score(lr, X_train, y_train, cv = kfold, scoring = 'roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541e582-ab63-4510-be2b-495d83647967",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_logreg,roc_auc_logreg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af149987-ead6-4f97-ba0f-be1e981b8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "logreg_matrix = metrics.confusion_matrix(y_test, np.round(y_rfe_pred,0))\n",
    "print(logreg_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90636fb-a295-4c6f-824b-ccb49224bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_matrix = metrics.confusion_matrix(y_test, np.round(y_pred,0))\n",
    "print(logreg_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d4cfc-63a1-40f9-a23d-89d3bf6ab994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 325.055482,
   "end_time": "2021-05-27T09:58:56.682533",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-27T09:53:31.627051",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
